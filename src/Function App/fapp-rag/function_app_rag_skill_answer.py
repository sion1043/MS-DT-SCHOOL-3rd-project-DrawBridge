import logging
import asyncio
from datetime import datetime, timezone, timedelta
from azure.cosmos.aio import CosmosClient
from azure.cosmos import PartitionKey
from azure.cosmos.exceptions import CosmosHttpResponseError
from azure.functions import TimerRequest, FunctionApp
import requests
import nest_asyncio

nest_asyncio.apply()
app = FunctionApp()

# -----------------------------
# Cosmos DB ì„¤ì •
# -----------------------------
COSMOS_ENDPOINT = ""
COSMOS_KEY = ""
COSMOS_DB = ""
SKILL_QUESTIONS_CONTAINER = ""
SKILL_ANSWERS_CONTAINER = ""

# -----------------------------
# Azure OpenAI ì„¤ì • (REST)
# -----------------------------
AZURE_OPENAI_KEY = ""
CHATGPT_ENDPOINT = ""
EMBEDDING_ENDPOINT = ""

HEADERS = {"Content-Type": "application/json", "api-key": AZURE_OPENAI_KEY}

# -----------------------------
# ë¹„ë™ê¸° ì¬ì‹œë„ í—¬í¼
# -----------------------------
async def retry_async(func, retries=3, delay=2, backoff=2):
    for attempt in range(retries):
        try:
            return await func()
        except (CosmosHttpResponseError, Exception) as e:
            logging.warning(f"âš ï¸ ì‹œë„ {attempt+1}/{retries} ì‹¤íŒ¨: {e}")
            if attempt < retries - 1:
                await asyncio.sleep(delay)
                delay *= backoff
            else:
                logging.error(f"âŒ ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼: {e}")
                return None

# -----------------------------
# GPT ì§ˆë¬¸ ë‹µë³€ ìƒì„±
# -----------------------------
async def generate_answers(question: str, skill_name: str, num_answers=10):
    prompt = (
        f"'{skill_name}' ìŠ¤í‚¬ì— ëŒ€í•œ ì§ˆë¬¸: \"{question}\"\n"
        f"ì´ ì§ˆë¬¸ì— ëŒ€í•´ **ìŠ¤í‚¬ ìˆ™ë ¨ë„ê°€ 1ë‹¨ê³„ì—ì„œ 10ë‹¨ê³„ê¹Œì§€ ì ì§„ì ìœ¼ë¡œ ë†’ì•„ì§€ë„ë¡** 10ê°œì˜ ë‹µë³€ì„ ë§Œë“¤ì–´ ì£¼ì„¸ìš”. "
        f"ê° ë‹µë³€ì€ **200~250ì ë‚´ì™¸**ë¡œ ì‘ì„±í•˜ê³ , ì„œë¡œ ê²¹ì¹˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤. "
        f"ë‹µë³€ì€ í•´ë‹¹ ìŠ¤í‚¬ ë¶„ì•¼ **ì „ë¬¸ê°€ ì‹œì ì—ì„œ ìƒì„¸í•˜ê²Œ** ì‘ì„±í•˜ê³ , ë‹¨ê³„ê°€ ì˜¬ë¼ê°ˆìˆ˜ë¡ ë‚œì´ë„ì™€ ìˆ™ë ¨ë„ê°€ ì¦ê°€í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. "
        f"ì¶œë ¥ í˜•ì‹ì€ ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„í•˜ê³  ë²ˆí˜¸ëŠ” ë¶™ì´ì§€ ë§ˆì„¸ìš”."
    )

    def sync_call():
        payload = {
            "messages": [
                {"role": "system", "content": "ë„ˆëŠ” ì±„ìš© í‰ê°€ ì „ë¬¸ê°€ë‹¤."},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 1200,
            "temperature": 0.8
        }
        resp = requests.post(CHATGPT_ENDPOINT, headers=HEADERS, json=payload)
        resp.raise_for_status()
        data = resp.json()
        text = data['choices'][0]['message']['content'].strip()
        answers = [a.strip() for a in text.split("\n") if a.strip()]
        return answers[:num_answers]

    return await asyncio.to_thread(sync_call)

# -----------------------------
# ì„ë² ë”© ìƒì„± (batch)
# -----------------------------
async def get_embeddings(texts: list[str]):
    def sync_call():
        payload = {"input": texts}
        resp = requests.post(EMBEDDING_ENDPOINT, headers=HEADERS, json=payload)
        resp.raise_for_status()
        data = resp.json()
        return [d["embedding"] for d in data["data"]]
    return await asyncio.to_thread(sync_call)

# -----------------------------
# í•˜ë‚˜ì˜ ì§ˆë¬¸ ì²˜ë¦¬ (ì¡°ê±´ ì²´í¬)
# -----------------------------
async def process_question(skill_doc, question_num, question, container, existing_keys: set):
    skill_id = skill_doc["skill_id"]
    skill_name = skill_doc["skill"]

    expected_ids = [f"{skill_id}_q{question_num}_a{i}" for i in range(1, 11)]
    existing_for_question = [eid for eid in expected_ids if eid in existing_keys]

    # ì¡°ê±´ 1: 10ê°œ ë‹¤ ìˆìœ¼ë©´ ê±´ë„ˆëœ€
    if len(existing_for_question) == 10:
        logging.info(f"{skill_id} Q{question_num} â†’ ì´ë¯¸ 10ê°œ ë‹µë³€ ì¡´ì¬, ê±´ë„ˆëœ€")
        return 0

    # ì¡°ê±´ 2: ì—†ê±°ë‚˜ ì¼ë¶€ë§Œ ìˆìœ¼ë©´ â†’ 1~10 ì „ë¶€ ìƒˆë¡œ ìƒì„± + ë®ì–´ì“°ê¸°
    answers = await retry_async(lambda: generate_answers(question, skill_name))
    if not answers:
        return 0

    embeddings = await retry_async(lambda: get_embeddings(answers))
    if not embeddings:
        return 0

    count = 0
    for i, (answer, embedding) in enumerate(zip(answers, embeddings), start=1):
        doc_id = f"{skill_id}_q{question_num}_a{i}"
        doc = {
            "id": doc_id,
            "skill_id": skill_id,
            "skill": skill_name,
            "question": question,
            "question_num": question_num,
            "answer": answer,
            "answer_num": i,
            "answer_embedding": embedding,
            "created_at": datetime.now(timezone(timedelta(hours=9))).isoformat(),
            "source": "gpt"
        }
        try:
            await container.upsert_item(doc)  # í•­ìƒ ë®ì–´ì“°ê¸°
            count += 1
        except CosmosHttpResponseError as e:
            logging.warning(f"Upsert ì‹¤íŒ¨: {doc_id} -> {e}")
    return count

# -----------------------------
# ìŠ¤í‚¬ ë‹¨ìœ„ ì²˜ë¦¬
# -----------------------------
async def process_skill(skill_doc, container, existing_keys: set):
    questions = skill_doc.get("questions", [])
    updated_count = 0
    for i, q in enumerate(questions, start=1):
        count = await process_question(skill_doc, i, q, container, existing_keys)
        updated_count += count
    return updated_count

# -----------------------------
# Timer Trigger
# -----------------------------
@app.schedule(
    schedule="0 0 3 * * *",
    arg_name="myTimer",
    run_on_startup=True,
    use_monitor=False
)
def main(myTimer: TimerRequest):
    logging.info("ğŸš€ Skill Answers ìƒì„± ì‹œì‘")
    asyncio.run(main_async())

# -----------------------------
# ë©”ì¸ ë¹„ë™ê¸° í•¨ìˆ˜
# -----------------------------
async def main_async():
    # Cosmos DB ì—°ê²°
    client = CosmosClient(COSMOS_ENDPOINT, COSMOS_KEY)
    db = client.get_database_client(COSMOS_DB)
    skill_questions_container = db.get_container_client(SKILL_QUESTIONS_CONTAINER)
    skill_answers_container = await db.create_container_if_not_exists(
        id=SKILL_ANSWERS_CONTAINER,
        partition_key=PartitionKey(path="/skill_id"),
        offer_throughput=400
    )

    # ê¸°ì¡´ ë°ì´í„° í‚¤ ì¡°íšŒ
    existing_keys = set()
    query = "SELECT c.id FROM c"
    async for item in skill_answers_container.query_items(query=query):
        existing_keys.add(item['id'])
    logging.info(f"âœ… ê¸°ì¡´ {len(existing_keys)}ê°œ ë°ì´í„° í™•ì¸ ì™„ë£Œ")

    # ëª¨ë“  ìŠ¤í‚¬ ì½ê¸°
    skills = []
    async for skill_doc in skill_questions_container.read_all_items():
        skills.append(skill_doc)
    logging.info(f"ì´ {len(skills)}ê°œì˜ ìŠ¤í‚¬ ì²˜ë¦¬ ì‹œì‘")

    # ìŠ¤í‚¬ ë™ì‹œ ì²˜ë¦¬
    sem = asyncio.Semaphore(10)
    async def sem_skill_task(skill_doc):
        async with sem:
            count = await process_skill(skill_doc, skill_answers_container, existing_keys)
            logging.info(f"{skill_doc['skill_id']} -> {count}ê°œ ë‹µë³€ ìƒì„±/ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            return count

    tasks = [sem_skill_task(skill_doc) for skill_doc in skills]
    results = await asyncio.gather(*tasks)
    total_answers = sum(results)
    logging.info(f"âœ… ì´ {total_answers}ê°œì˜ ë‹µë³€ ìƒì„± ë° ì €ì¥ ì™„ë£Œ")
